version: '3.8'

services:
  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # LM Studio (for local development only)
  # lmstudio:
  #   image: lmstudio/lmstudio:latest
  #   ports:
  #     - "1234:1234"
  #   volumes:
  #     - ./models:/models
  #   environment:
  #     - MODEL_PATH=/models/lmstudio-community/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf

  # FastAPI Application
  app:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - ./Scripts:/app/Scripts
      - ./templates:/app/templates
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - LMSTUDIO_URL=http://host.docker.internal:1234/v1/chat/completions
    depends_on:
      qdrant:
        condition: service_healthy
    restart: unless-stopped

volumes:
  qdrant_storage:
